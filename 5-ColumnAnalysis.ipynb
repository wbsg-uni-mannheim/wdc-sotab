{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2c86315",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import ast\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "import multiprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e386df9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "minimum10 = pd.read_csv('output-data/statistics/expanded_tables_annotations.csv')\n",
    "minimum10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07e2d349",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Total number of columns:\n",
    "minimum10['column_count'].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "760a24ca",
   "metadata": {},
   "source": [
    "#### For each table note which columns can be annotated by the selected labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "437cfa68",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_to_dict = minimum10.to_dict('records')\n",
    "selected = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25e85f51",
   "metadata": {},
   "outputs": [],
   "source": [
    "for row in selected_to_dict:\n",
    "    keys = ast.literal_eval(row['all_cols']).keys()\n",
    "    selected[row['file_name']] = list(keys)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39a9a1f9",
   "metadata": {},
   "source": [
    "### Functions for preprocessing of text columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f1384e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load English stopwords and initialize stemmer\n",
    "english_stopwords = stopwords.words('english')\n",
    "stemmer = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8f8afc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to return a flattened list (open nested lists)\n",
    "def flatten_list(original_list):\n",
    "    flat_list = []\n",
    "    for item in original_list:\n",
    "        if isinstance(item, list):\n",
    "            flat_list = flat_list + item\n",
    "        else:\n",
    "            flat_list.append(item)\n",
    "    return flat_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef8e521f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function for lower casing, removing punctuation and special characters, remove english stopwords and apply stemming\n",
    "def clean_text(text):\n",
    "    #5: Lower case\n",
    "    text = str(text).lower()\n",
    "    \n",
    "    #8: Remove punctuation and special characters\n",
    "    text = re.sub(r'[^a-zA-Z0-9]+', ' ', text)\n",
    "    \n",
    "    #9: Remove English stopwords\n",
    "    pat = r'\\b(?:{})\\b'.format('|'.join(english_stopwords))\n",
    "    text = re.sub(pat, '', str(text))\n",
    "    \n",
    "    #Apply stemming\n",
    "    stems = []\n",
    "    \n",
    "    for word in text.split():\n",
    "        if word not in english_stopwords:\n",
    "            stems.append(stemmer.stem(word))\n",
    "    text = ' '.join(stems)\n",
    "    \n",
    "    #Remove excess whitespaces\n",
    "    text = re.sub(' +', ' ', str(text)).strip()\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aeab5672",
   "metadata": {},
   "source": [
    "### Tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d8527f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "tables = minimum10['file_name'].tolist()\n",
    "\n",
    "#Existing English Tables\n",
    "existing = open(\"output-data/english_table_names.txt\", 'r')\n",
    "existing_english_tables = [line.replace('\\n', '') for line in existing.readlines()]\n",
    "\n",
    "#Import all datetime labels from schema.org\n",
    "datetime = open(\"data/schemaorg-vocabulary/datetime_labels.txt\", 'r')\n",
    "date_labels = [line.replace('\\n', '').lower() for line in datetime.readlines()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "141a6bb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Returns values of numerical columns\n",
    "def num_values(file_name):\n",
    "    \n",
    "    if file_name in existing_english_tables:\n",
    "        file = 'output-data/expanded-tables/' + file_name\n",
    "    else:\n",
    "        file = 'output-data/new-english-tables/' + file_name\n",
    "    \n",
    "    #Open table\n",
    "    df = pd.read_json(file, compression='gzip', lines=True)\n",
    "\n",
    "    #Select only numerical columns\n",
    "    df = df.select_dtypes(include=['number'])\n",
    "    \n",
    "    num_props = {}\n",
    "\n",
    "    for column_name in df.columns:\n",
    "        if (column_name in selected[file_name]) and (column_name not in date_labels and 'date' not in column_name) : #For selected columns only\n",
    "            num_props[column_name] = df[df[column_name].notna()][column_name].tolist()\n",
    "\n",
    "    return num_props"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60b950fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "pool = multiprocessing.Pool(processes=30)\n",
    "numerical_values = pool.map(num_values, tables)\n",
    "pool.close()\n",
    "pool.join()\n",
    "\n",
    "num_tab = []\n",
    "for i, val in numerical_values:\n",
    "    class_ = tables[i].split('_')[0]\n",
    "    for col in val:\n",
    "        num_tab.append([class_, col, tables[i],val[col]])\n",
    "\n",
    "num_df = pd.DataFrame(num_tab, columns = ['class', 'column_name', 'file_name',\"value\"])\n",
    "num_df.to_csv('output-data/statistics/numcols.csv.gz', index=False, compression='gzip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a1e1872",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Returns values of datetime columns\n",
    "def date_values(file_name):    \n",
    "    if file_name in existing_english_tables:\n",
    "        file = 'output-data/expanded-tables/' + file_name\n",
    "    else:\n",
    "        file = 'output-data/new-english-tables/' + file_name\n",
    "    \n",
    "    #Open table\n",
    "    df = pd.read_json(file, compression='gzip', lines=True)\n",
    "    \n",
    "    #Exclude numerical columns\n",
    "    df = df.select_dtypes(exclude=['number'])\n",
    "        \n",
    "    date_props = {}\n",
    "\n",
    "    for column_name in df.columns:\n",
    "        if ':' in column_name:\n",
    "            if column_name.split(':')[1] in date_labels or 'date' in column_name:\n",
    "                date_props[column_name] = df[df[column_name].notna()][column_name].tolist()\n",
    "        else:\n",
    "            if column_name in date_labels or 'date' in column_name:\n",
    "                date_props[column_name] = df[df[column_name].notna()][column_name].tolist()\n",
    "                \n",
    "    return date_props"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25874895",
   "metadata": {},
   "outputs": [],
   "source": [
    "pool = multiprocessing.Pool(processes=30)\n",
    "datetime_values = pool.map(date_values, tables)\n",
    "pool.close()\n",
    "pool.join()\n",
    "\n",
    "date_tab = []\n",
    "for i, val in datetime_values:\n",
    "    class_ = tables[i].split('_')[0]\n",
    "    for col in val:\n",
    "        date_tab.append([class_, col, tables[i],val[col]])\n",
    "\n",
    "date_df = pd.DataFrame(date_tab, columns = ['class', 'column_name', 'file_name','value'])\n",
    "date_df.to_csv('output-data/statistics/datecols.csv.gz', index=False, compression='gzip')\n",
    "date = list(set(date_df['column_name'].tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45cc7df8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Returns values of cleaned textual columns\n",
    "def text_values(file_name):\n",
    "    \n",
    "    if file_name in existing_english_tables:\n",
    "        file = 'output-data/expanded-tables/' + file_name\n",
    "    else:\n",
    "        file = 'output-data/new-english-tables/' + file_name\n",
    "    \n",
    "    #Open table\n",
    "    df = pd.read_json(file, compression='gzip', lines=True)\n",
    "    \n",
    "    #Exclude numerical columns\n",
    "    df = df.select_dtypes(exclude=['number'])\n",
    "    \n",
    "    text_props = []\n",
    "\n",
    "    for column_name in df.columns:\n",
    "        if column_name not in date:\n",
    "            text_props.append(column_name)\n",
    "                \n",
    "    return text_props"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52728926",
   "metadata": {},
   "outputs": [],
   "source": [
    "pool = multiprocessing.Pool(processes=30)\n",
    "textual_values = pool.map(text_values, tables)\n",
    "pool.close()\n",
    "pool.join()\n",
    "\n",
    "text_tab = []\n",
    "for i, val in textual_values:\n",
    "    class_ = tables[i].split('_')[0]\n",
    "    for col in val:\n",
    "        text_tab.append([class_, col, tables[i]])\n",
    "\n",
    "text_df = pd.DataFrame(text_tab, columns = ['class', 'column_name', 'file_name'])\n",
    "text_df.to_csv('output-data/statistics/textcols.csv.gz', index=False, compression='gzip')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
