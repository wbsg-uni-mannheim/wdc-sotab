{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb67e2b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import ast\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "babd9606",
   "metadata": {},
   "outputs": [],
   "source": [
    "cta_statistics = pd.read_csv('output-data/statistics/cta_statistics.csv')\n",
    "cta_statistics = cta_statistics.loc[~pd.isnull(cta_statistics['cta_label'])]\n",
    "cta_statistics = cta_statistics.loc[cta_statistics['column_count'] >= 50]\n",
    "cta_statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbb6e14d",
   "metadata": {},
   "outputs": [],
   "source": [
    "annotated_tables = pd.read_csv('output-data/statistics/expanded_tables_annotations.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fba6782b",
   "metadata": {},
   "outputs": [],
   "source": [
    "type_lbls = {}\n",
    "for index, row in annotated_tables.iterrows():\n",
    "    for col in eval(row['type_labels']):\n",
    "        if eval(row['type_labels'])[col] != None and eval(row['type_labels'])[col] != 'Wrong':\n",
    "            type_lbls[col+'_'+row['file_name']] = eval(row['type_labels'])[col].strip() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38f6d6c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Choose tables with more than 3 columns\n",
    "tabs = pd.read_csv('output-data/statistics/expanded_tables_annotations_cta.csv')\n",
    "tabs = tabs.loc[(tabs['column_count'] >= 3)]\n",
    "tabs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f54a6f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_names = set(tabs['file_name'].tolist())\n",
    "len(file_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "728b8008",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Columns to ignore in selection with a density less than 70%\n",
    "ignore = []\n",
    "tables_to_dict = annotated_tables.to_dict('records')\n",
    "for table in tables_to_dict:\n",
    "    for col in eval(table['all_cols']):\n",
    "        if eval(table['all_cols'])[col] < 70:\n",
    "            ignore.append(col+'_'+table['file_name'])\n",
    "ignore = set(ignore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c768a0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a file to hold already selected columns from tables and their selection type\n",
    "# Selection type: 'Missing values', 'Intra similarity', 'Inter simimilarity/dissimilarity', 'format heterogeneity'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b51691ee",
   "metadata": {},
   "source": [
    "## 1. Corner Cases Columns Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae850590",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_sim = pd.read_csv('output-data/similarities/subset8000_num_sim_cta.csv.gz', compression='gzip')\n",
    "num_sim2 = pd.read_csv('output-data/similarities/subset7000_num_sim_cta.csv.gz', compression='gzip')\n",
    "date_sim = pd.read_csv('output-data/similarities/subset6000_datetime_sim.csv.gz', compression='gzip')\n",
    "date_sim2 = pd.read_csv('output-data/similarities/subset6000_2_datetime_sim.csv.gz', compression='gzip')\n",
    "text_sim = pd.read_csv('output-data/similarities/subset219000_textcols_coltype_sim.csv.gz', compression='gzip')\n",
    "text_sim2 = pd.read_csv('output-data/similarities/subset150000_textcols_coltype_sim.csv.gz', compression='gzip')\n",
    "similarities = pd.concat([num_sim, num_sim2, date_sim, date_sim2, text_sim, text_sim2], ignore_index=True)\n",
    "similarities['file_name'] = similarities['col_name'].apply(lambda row: row.split('_')[1]+'_'+row.split('_')[2]+'_'+row.split('_')[3])\n",
    "similarities = similarities.loc[similarities['file_name'].isin(file_names)]\n",
    "similarities = similarities.loc[~similarities['col_name'].isin(ignore)]\n",
    "similarities"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05e44397",
   "metadata": {},
   "source": [
    "### Select intra similarity columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0311a542",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Column -> its similar cols\n",
    "intra_similarities = {}\n",
    "for index, row in similarities.iterrows():\n",
    "    col_name, class_name, table_name, ending = row['col_name'].split('_')\n",
    "    file_name = '_'.join([class_name, table_name, ending])\n",
    "    \n",
    "    #If correct column\n",
    "    if row['col_name'] in type_lbls and (type_lbls[row['col_name']] != None or type_lbls[row['col_name']] != 'Wrong'):\n",
    "        \n",
    "        #Look at only its 10 most similar columns\n",
    "        similar_cols = row['similar_cols'].split('; ')[:10]\n",
    "        intra_similarities[row['col_name']] = []\n",
    "\n",
    "        for col in similar_cols:\n",
    "            col_name2, class_name2, table_name2, ending2 = col.split('_')\n",
    "            file_name_2 = '_'.join([class_name2, table_name2, ending2])\n",
    "\n",
    "            # More than 70% of density, same table and in selected tables for CPA\n",
    "            if col in type_lbls and file_name_2 in file_names and file_name == file_name_2 and col not in ignore:\n",
    "                if type_lbls[row['col_name']] != type_lbls[col]:\n",
    "                    if (type_lbls[col] != 'None' or type_lbls[col] != 'Wrong'):\n",
    "                        intra_similarities[row['col_name']].append(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ad23745",
   "metadata": {},
   "outputs": [],
   "source": [
    "intra_tables = {} # Mark which columns can be selected in each table\n",
    "intra_cols = set() # Which columns selected overall\n",
    "intra_class = {} # How many columns per schema.org type/class\n",
    "intra_labels = {}\n",
    "\n",
    "for key in intra_similarities:\n",
    "    if intra_similarities[key]:\n",
    "        \n",
    "        col_name, class_, table_name, ending = key.split('_')\n",
    "        file_name = '_'.join([class_, table_name, ending])\n",
    "        label = type_lbls[key]\n",
    "        \n",
    "        if file_name not in intra_tables:\n",
    "            intra_tables[file_name] = set()\n",
    "        \n",
    "        if class_ not in intra_class:\n",
    "            intra_class[class_] = 0\n",
    "            \n",
    "        if label not in intra_labels:\n",
    "            intra_labels[label] = []\n",
    "            \n",
    "        if key not in intra_labels[label]:\n",
    "            intra_labels[label].append(key)\n",
    "            \n",
    "        intra_cols.add(key)\n",
    "        intra_tables[file_name].add(key)\n",
    "        intra_class[class_] += 1\n",
    "        \n",
    "        for col in intra_similarities[key]:\n",
    "            label = type_lbls[col]\n",
    "            \n",
    "            if label not in intra_labels:\n",
    "                intra_labels[label] = []\n",
    "            \n",
    "            if col not in intra_labels[label]:\n",
    "                intra_labels[label].append(col)\n",
    "            \n",
    "            intra_cols.add(col)\n",
    "            intra_tables[file_name].add(col)\n",
    "            intra_class[class_] += 1\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5154fa5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Mark all selected columns in a dictionary:\n",
    "selected_cols_tables = {}\n",
    "\n",
    "for table in intra_tables:\n",
    "    \n",
    "    selected_cols_tables[table] = {}\n",
    "    for col in intra_tables[table]:\n",
    "        selected_cols_tables[table][col.split('_')[0]] = 'Intra similarity'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a03bda2",
   "metadata": {},
   "outputs": [],
   "source": [
    "low_class = [] #Schema.org types that have less than 1500 selected columns until now\n",
    "low_label = [] #CTA labels that have less than 100 examples until now\n",
    "\n",
    "for cl in intra_class:\n",
    "    if intra_class[cl] < 1500:\n",
    "        low_class.append(cl)\n",
    "        \n",
    "for lb in intra_labels:\n",
    "    if len(intra_labels[lb]) < 100:\n",
    "        low_label.append(lb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ad93400",
   "metadata": {},
   "source": [
    "### Select inter table similarity columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bf50c46",
   "metadata": {},
   "outputs": [],
   "source": [
    "inter_similarities = {}\n",
    "for index, row in similarities.iterrows():\n",
    "    col_name, class_name, table_name, ending = row['col_name'].split('_')\n",
    "    file_name = '_'.join([class_name, table_name, ending])\n",
    "        \n",
    "    #If correct column\n",
    "    if row['col_name'] in type_lbls and type_lbls[row['col_name']] != None and type_lbls[row['col_name']] != 'Wrong':\n",
    "        #Look at 10 most similar columns\n",
    "        similar_cols = row['similar_cols'].split('; ')[:10]\n",
    "        inter_similarities[row['col_name']] = []\n",
    "\n",
    "        for col in similar_cols:\n",
    "            col_name2, class_name2, table_name2, ending2 = col.split('_')\n",
    "            file_name_2 = '_'.join([class_name2, table_name2, ending2])\n",
    "\n",
    "            if col in type_lbls and file_name_2 in file_names and file_name != file_name_2 and col not in ignore:\n",
    "                if type_lbls[row['col_name']] != type_lbls[col]:\n",
    "                    if (type_lbls[col] != None and type_lbls[col] != 'Wrong'):\n",
    "                        inter_similarities[row['col_name']].append(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7501c975",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Select columns that have at least one similar column\n",
    "inter_sims = [ [x] + inter_similarities[x] for x in inter_similarities if len(inter_similarities[x]) > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51b81d8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selecting inter similarities: \n",
    "#Count how many columns for low class number of columns and for low CTA labels can be selected\n",
    "select_test = []\n",
    "i = 0\n",
    "\n",
    "for cols in inter_sims:\n",
    "    select_test.append([])\n",
    "    \n",
    "    for col in cols:\n",
    "        #class_ = col.split('_')[1]\n",
    "        \n",
    "        col_name, class_name, table_name, ending = col.split('_')\n",
    "        table = '_'.join([class_name, table_name, ending])\n",
    "        \n",
    "        #If table is in low class and in low label\n",
    "        if class_name in low_class and type_lbls[col] in low_label:\n",
    "            #If it hasn't been selected already in the intra similarity phase\n",
    "            if (table in selected_cols_tables and col_name not in selected_cols_tables[table]) or table not in selected_cols_tables:\n",
    "                select_test[i].append(col)\n",
    "    i+=1\n",
    "    \n",
    "    \n",
    "# And Filter out columns with less than 1 similar column\n",
    "s = [ x for x in select_test if len(x) > 1]\n",
    "\n",
    "\n",
    "# And Select maximum 3500 cols for each CTA label\n",
    "sel_labels = {}\n",
    "\n",
    "for sim in s:\n",
    "    for col in sim:\n",
    "        \n",
    "        if type_lbls[col] not in sel_labels:\n",
    "            sel_labels[type_lbls[col]] = []\n",
    "        \n",
    "        if len(sel_labels[type_lbls[col]]) < 3500:\n",
    "            sel_labels[type_lbls[col]].append(col)\n",
    "\n",
    "sel_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49da607c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Select columns which are included in sel_labels\n",
    "selected_test_2 = []\n",
    "i = 0\n",
    "\n",
    "for cols in inter_sims:\n",
    "    selected_test_2.append([])\n",
    "    \n",
    "    for col in cols:\n",
    "        if type_lbls[col] in sel_labels and col in sel_labels[type_lbls[col]]:\n",
    "            selected_test_2[i].append(col)\n",
    "        \n",
    "    i+=1\n",
    "\n",
    "#Filter out columns with no similar columns\n",
    "s_2 = [ x for x in selected_test_2 if len(x) > 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6721b8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the new selected columns to the already selected ones\n",
    "selected_cols = copy.deepcopy(selected_cols_tables)\n",
    "for s in s_2:\n",
    "    for col in s:\n",
    "        tab = col.split('_')[1] + '_' + col.split('_')[2] + '_' + col.split('_')[3]\n",
    "        \n",
    "        if tab not in selected_cols:\n",
    "            selected_cols[tab] = {}\n",
    "        \n",
    "        selected_cols[tab][col.split('_')[0]] = 'Inter Similarity'\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d86d42f",
   "metadata": {},
   "source": [
    "## 2. Select Missing values columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e0a0b88",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Choose some low density tables\n",
    "low_dens_70 = annotated_tables.loc[ (annotated_tables['overall_table_density'] < 70) ]\n",
    "low_dens_70"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e2ac060",
   "metadata": {},
   "outputs": [],
   "source": [
    "#How many low density columns can be annotated per table\n",
    "low_dens_70['low_cols'] = low_dens_70['all_cols'].apply(lambda row: len( [x for x in eval(row) if eval(row)[x] < 70 and eval(row)[x] > 10 ] ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "194c3d59",
   "metadata": {},
   "outputs": [],
   "source": [
    "low_dens_70.loc[ (low_dens_70['low_cols'] >= 3) ].groupby(['class'])['low_cols'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "003bf040",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Limit Product, Recipe and Event tables to 800\n",
    "prods = low_dens_70.loc[ (low_dens_70['low_cols'] >= 3) & (low_dens_70['class'] == 'Product' ) ][1000:]\n",
    "recipe = low_dens_70.loc[ (low_dens_70['low_cols'] >= 3) & (low_dens_70['class'] == 'Recipe' ) ][1000:]\n",
    "event = low_dens_70.loc[ (low_dens_70['low_cols'] >= 3) & (low_dens_70['class'] == 'Event' ) ][1000:]\n",
    "\n",
    "remove_tables = prods['file_name'].tolist() + recipe['file_name'].tolist() + event['file_name'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6033fcb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Select columns with low density from the low density tables that have at least 3 low density columns\n",
    "#Add to all other selected columns\n",
    "\n",
    "for index, row in low_dens_70.iterrows():\n",
    "    file_name = row['file_name']\n",
    "    \n",
    "    if file_name not in remove_tables:\n",
    "        if file_name not in selected_cols:\n",
    "            selected_cols[file_name] = {}\n",
    "\n",
    "        #Look at low density columns and select if not already annotated from corner cases\n",
    "        annotated_cols = eval(row['all_cols'])\n",
    "\n",
    "        for column in annotated_cols:\n",
    "            if annotated_cols[column] < 70 and annotated_cols[column] > 10 and column not in selected_cols[file_name]:\n",
    "                selected_cols[file_name][column] = 'Missing values'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28e72b98",
   "metadata": {},
   "source": [
    "## 3. Select value format heterogeneity columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3313f5a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Select the same columns that were selected for CPA excpet from some datetime columns\n",
    "selection_cpa = pd.read_csv('output-data/cpa-datasets/selected_1_2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "972162f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "selection = annotated_tables.loc[ annotated_tables['file_name'].isin(selected_cols) ]\n",
    "selection['selected_cols'] = selected_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "688a9114",
   "metadata": {},
   "outputs": [],
   "source": [
    "count_value = {}\n",
    "\n",
    "for index, row in selection_cpa.iterrows():\n",
    "    types = eval(row['type_labels'])\n",
    "    for col in eval(row['selected_cols']):\n",
    "        col_file = col + '_' + row['file_name']\n",
    "        \n",
    "        if col != 'basesalary' and col != 'estimatedsalary' and col != 'basesalary' and col != 'nutrition:servingsize' and col != 'size' and col not in ignore and col_file in type_lbls:\n",
    "            if eval(row['selected_cols'])[col] == 'Value Heterogeneity':\n",
    "                if (row['file_name'] in selected_cols and col not in selected_cols[row['file_name']]) or row['file_name'] not in selected_cols:\n",
    "                    \n",
    "                    if type_lbls[col_file] not in count_value:\n",
    "                        count_value[type_lbls[col_file]] = 0\n",
    "                    \n",
    "                    \n",
    "                    if count_value[type_lbls[col_file]] < 2000:\n",
    "                        count_value[type_lbls[col_file]] += 1\n",
    "                        \n",
    "                        if row['file_name'] not in selected_cols:\n",
    "                            selected_cols[row['file_name']] = {}\n",
    "                        selected_cols[row['file_name']][col] = 'Value Heterogeneity'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfcc6d35",
   "metadata": {},
   "source": [
    "## 4. Select random columns for all labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c95f902b",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_cta = cta_statistics['cta_label'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65c0b012",
   "metadata": {},
   "outputs": [],
   "source": [
    "selection = annotated_tables.loc[ annotated_tables['file_name'].isin(selected_cols) ]\n",
    "sel_cols = []\n",
    "for index, row in selection.iterrows():\n",
    "    sel_cols.append(selected_cols[row['file_name']])\n",
    "selection['selected_cols'] = sel_cols\n",
    "selection['selected_cols_number'] = selection['selected_cols'].apply(lambda row: len(row))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ead79165",
   "metadata": {},
   "outputs": [],
   "source": [
    "selection_dict = selection.to_dict('records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a838ab46",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Select from already selected tables all non-annotated columns with a limit of 6500 columns\n",
    "count_class = {} #Count columns per Schema.org type/class\n",
    "type_count = {} #Count columns per CTA label\n",
    "\n",
    "for tab in selection_dict:\n",
    "    sel = tab['selected_cols']\n",
    "    \n",
    "    if tab['class'] not in count_class:\n",
    "        count_class[tab['class']] = 0\n",
    "    \n",
    "    #Select a maximum of 6500 columns per Schema.org type/class \n",
    "    if count_class[tab['class']] < 6500 and col+'_'+row['file_name'] not in ignore :\n",
    "    \n",
    "        for col in eval(tab['all_cols']):\n",
    "            #If column has not been yet selected:\n",
    "            if col not in sel and col+'_'+row['file_name'] in type_lbls:\n",
    "                count_class[tab['class']] += 1\n",
    "                \n",
    "                #Add to selected\n",
    "                selected_cols[tab['file_name']][col] = 'Random'\n",
    "\n",
    "                if type_lbls[col+'_'+tab['file_name']] not in type_count:\n",
    "                    type_count[type_lbls[col+'_'+tab['file_name']]] = 0\n",
    "\n",
    "                type_count[type_lbls[col+'_'+tab['file_name']]] += 1\n",
    "\n",
    "\n",
    "#             elif col in type_lbls:\n",
    "#                 if type_lbls[col+'_'+tab['file_name']] not in type_count:\n",
    "#                     type_count[type_lbls[col+'_'+tab['file_name']]] = 0\n",
    "\n",
    "#                 type_count[type_lbls[col+'_'+tab['file_name']]] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5447ae42",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_cta = all_cta + list(type_count.keys())\n",
    "all_cta = list(set(all_cta))\n",
    "#Mark only labels that have not yet reached at least 100 examples\n",
    "for c in all_cta:\n",
    "    if c in type_count and type_count[c] >= 100: \n",
    "        all_cta.remove(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37897d02",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Add more examples to CTA labels that have not reached enough examples\n",
    "count_class_2 = {} #Count columns per Schema.org type, do not pass 6500 columns\n",
    "\n",
    "for cl in count_class:\n",
    "    count_class_2[cl] = 0\n",
    "    if count_class[cl] < 2000:\n",
    "        d = annotated_tables.loc[(~annotated_tables['file_name'].isin(selected_cols)) & (annotated_tables['class'] == cl ) & (annotated_tables['overall_table_density'] >= 70 )]\n",
    "        \n",
    "        for index, row in d.iterrows():\n",
    "            for col in eval(row['all_cols']):\n",
    "                if col+'_'+row['file_name'] in type_lbls and col+'_'+row['file_name'] not in ignore:\n",
    "                    \n",
    "                    if type_lbls[col+'_'+row['file_name']] not in type_count:\n",
    "                        type_count[type_lbls[col+'_'+row['file_name']]] = 0\n",
    "                    \n",
    "                    if type_count[type_lbls[col+'_'+row['file_name']]] < 2000:\n",
    "                        if count_class_2[cl] < (6500 - count_class[cl]):\n",
    "                            if row['file_name'] not in selected_cols:\n",
    "                                selected_cols[row['file_name']] = {}\n",
    "                            \n",
    "                            selected_cols[row['file_name']][col] = 'Random 2'\n",
    "                            count_class_2[cl] += 1\n",
    "                            type_count[type_lbls[col+'_'+row['file_name']]] +=1\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce3d71a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Select maximum 300 columns per CTA label\n",
    "new_cols = {}\n",
    "for l in all_cta:\n",
    "    new_cols[l] = []\n",
    "\n",
    "for index, row in annotated_tables.sort_values('column_count', ascending=False).iterrows():\n",
    "    types = eval(row['type_labels'])\n",
    "    \n",
    "    for col in eval(row['all_cols']):\n",
    "        if types[col] in all_cta and len(new_cols[types[col]]) < 300 and col+'_'+row['file_name'] in type_lbls and col+'_'+row['file_name'] not in ignore:      \n",
    "            if row['file_name'] not in selected_cols or col not in selected_cols[row['file_name']]:\n",
    "                \n",
    "                new_cols[types[col]].append(col+'_'+row['file_name'])\n",
    "                \n",
    "                #add to selected columns\n",
    "                if row['file_name'] not in selected_cols:\n",
    "                    selected_cols[row['file_name']] = {}\n",
    "                selected_cols[row['file_name']][col] = 'Random 3'\n",
    "                "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53855309",
   "metadata": {},
   "source": [
    "## Assemble all selected columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ab640fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "selection = annotated_tables.loc[ annotated_tables['file_name'].isin(selected_cols) ]\n",
    "sel_cols = []\n",
    "for index, row in selection.iterrows():\n",
    "    sel_cols.append(selected_cols[row['file_name']])\n",
    "selection['selected_cols'] = sel_cols\n",
    "selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de062c0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = []\n",
    "for index, row in selection.iterrows():\n",
    "    rel_labels = eval(row['rel_labels'])\n",
    "    type_labels = eval(row['type_labels'])\n",
    "    densities = eval(row['all_cols'])\n",
    "    \n",
    "    for cols in selected_cols[row['file_name']]:\n",
    "        if cols in rel_labels and cols in type_labels:\n",
    "            res.append([row['class'], cols, row['file_name'], rel_labels[cols], type_lbls[cols+'_'+row['file_name']], densities[cols], selected_cols[row['file_name']][cols] ])\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "586433dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.DataFrame(res, columns=['class', 'column_name', 'file_name', 'relation_label', 'type_label', 'density', 'selection_type'])\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0ab44cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['selection_type'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ae19915",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.loc[dataset['density'] >= 10 ]\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f272657",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove columns belonging to CTA labels that do not have a minimum of 50 examples\n",
    "s = dataset.groupby(['type_label'])['column_name'].count()\n",
    "no_rels = list(s[s < 50].keys())\n",
    "dataset = dataset.loc[~dataset['type_label'].isin(no_rels)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa3fbb79",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b96333e",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(dataset['type_label'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d815db7",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(dataset['file_name'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64c64dfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['selection_type'].replace(['Intra similarity','Inter Similarity'], 'Corner Cases', inplace=True)\n",
    "dataset['selection_type'].replace(['Random', 'Random 2', 'Random 3'], 'Random', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8e7288c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.to_csv('output-data/cta-datasets/dataset_cta.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
