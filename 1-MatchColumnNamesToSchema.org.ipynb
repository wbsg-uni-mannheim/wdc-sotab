{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcfd5765",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import zipfile\n",
    "import pandas as pd\n",
    "import os\n",
    "import json\n",
    "import re\n",
    "import ast\n",
    "import matplotlib\n",
    "import multiprocessing\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67e41434",
   "metadata": {},
   "source": [
    "## Unzip top100 and minimum3 tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1651535",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Path where all downloaded top100 and minimum3 zip files are:\n",
    "original_data_path = 'data/stc-zip-files/'\n",
    "\n",
    "#Unzip all Schema.org Table corpus files in directory: data/original-corpus-data\n",
    "#Can take a few hours\n",
    "unzipped_path = 'data/original-corpus-data/'\n",
    "for file in os.listdir(unzipped_path):\n",
    "    with zipfile.ZipFile(unzipped_path + file, 'r') as zip_ref:\n",
    "        zip_ref.extractall(original_data_path)\n",
    "\n",
    "tables = os.listdir(original_data_path)\n",
    "len(tables)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "892c32f7",
   "metadata": {},
   "source": [
    "## Create Statistic files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2dcc6e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_table_statistics(file_name):\n",
    "    \n",
    "    file = 'data/stc-zip-files/' + file_name\n",
    "    \n",
    "    df = pd.read_json(file, compression='gzip', lines=True)\n",
    "    df.drop(['row_id', 'page_url'], axis=1, inplace=True)\n",
    "    \n",
    "    try:\n",
    "        number_of_rows = len(df.index)\n",
    "        column_count = len(df.columns)\n",
    "        empty_cells = df.isna().sum().sum()\n",
    "        total_cells = number_of_rows * column_count\n",
    "\n",
    "        column_name_and_density = {}\n",
    "        overall_table_density = int((total_cells - empty_cells)/total_cells *100)\n",
    "\n",
    "        for index, column in df.isna().sum().iteritems():\n",
    "            column_name_and_density[index] = int(((number_of_rows - column) / number_of_rows) * 100)\n",
    "\n",
    "        return [ file_name, number_of_rows, column_count, column_name_and_density, overall_table_density ]\n",
    "    \n",
    "    except ValueError:\n",
    "        print(file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77a87826",
   "metadata": {},
   "outputs": [],
   "source": [
    "pool = multiprocessing.Pool(processes=30)\n",
    "res = pool.map(get_table_statistics, tables)\n",
    "pool.close()\n",
    "pool.join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02ccead0",
   "metadata": {},
   "outputs": [],
   "source": [
    "r = [re for re in res if re]\n",
    "statistics = pd.DataFrame(r, columns=['file_name', 'number_of_rows', 'column_count', 'column_name_and_density', 'overall_table_density'])\n",
    "statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c51bd2b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "statistics.to_csv('output-data/statistics/table_statistics.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d54e4b5",
   "metadata": {},
   "source": [
    "## Choose tables with at least 10 rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2c1acd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "minimum10 = statistics.loc[statistics['number_of_rows'] >= 10]\n",
    "minimum10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f114cbb",
   "metadata": {},
   "source": [
    "## Column Names Statistics \n",
    "Re-arrange tables by unique column names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37209f6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "min10_dict = minimum10.to_dict('records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48136299",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "min10_dict[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f5da3c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Add to a dictionary column names grouped by their class as keys and number of rows, columns and file_names as values\n",
    "colnames = {}\n",
    "for row in min10_dict:\n",
    "    class_ = row['file_name'].split('_')[0]\n",
    "    cols = row['column_name_and_density']\n",
    "    \n",
    "    if class_ not in colnames:\n",
    "        colnames[class_] = {}\n",
    "    \n",
    "    for col in cols:\n",
    "        if col in colnames[class_]:\n",
    "            colnames[class_][col].append([row['number_of_rows'], cols[col], row['file_name'], row['overall_table_density']])\n",
    "        else:\n",
    "            colnames[class_][col] = [[row['number_of_rows'], cols[col], row['file_name'], row['overall_table_density']]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abc836ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Turn the dictionary with the column names into a dataframe\n",
    "allcols = []\n",
    "for classes in colnames:\n",
    "    for colname in colnames[classes]:\n",
    "        total_rows = 0\n",
    "        tables_and_density = {}\n",
    "        \n",
    "        for tabs in colnames[classes][colname]:\n",
    "            total_rows += tabs[0]\n",
    "            #Museum_takemetotheworld.com_September2020.json.gz: overall_table_density, column density in this table\n",
    "            tables_and_density[tabs[2]] = [tabs[3], tabs[1]] \n",
    "        \n",
    "        allcols.append([classes, colname, len(colnames[classes][colname]), total_rows, tables_and_density])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7a892c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_cols = pd.DataFrame(allcols, columns=['class', 'column_name', 'table_number', 'row_number', 'table_and_density'])\n",
    "all_cols"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87d51500",
   "metadata": {},
   "source": [
    "## Match to Schema.org Properties and Types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dea13c48",
   "metadata": {},
   "outputs": [],
   "source": [
    "#For each property file, read its propstotypes file and match expected types\n",
    "result_all = []\n",
    "\n",
    "for index, row in all_cols.iterrows():\n",
    "    col_name = str(row['column_name'])\n",
    "    class_ = row['class']\n",
    "        \n",
    "    types = pd.read_csv('data/PropsToTypes/' + class_ + '_propsToTypes.csv')\n",
    "    find_label = (row['class'] + '.' + str(row['column_name'])).lower()\n",
    "    is_label = types.loc[ types['property'].str.lower() == find_label ]\n",
    "    \n",
    "    final_label = ''\n",
    "    final_type = ''\n",
    "\n",
    "    if(len(is_label) != 0):\n",
    "        idx = is_label.index.tolist()[0]\n",
    "        final_label = is_label['property'][idx]\n",
    "        final_type = is_label['expected_types'][idx]\n",
    "\n",
    "    result_all.append([class_, col_name, final_label, final_type, row['table_number'], row['row_number'], row['table_and_density']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8c19941",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "cols_to_schema = pd.DataFrame(result_all, columns=['class', 'column_name', 'relation_label', 'type_label', 'table_number','row_number','table_and_density'])\n",
    "cols_to_schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "767e8037",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Filter out column names that did not match any schema.org property = are wrong\n",
    "cols = cols_to_schema.loc[(cols_to_schema['relation_label'] != '')]\n",
    "cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdbeff43",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols.to_csv('output-data/statistics/column_label_mapping.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbe26535",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
