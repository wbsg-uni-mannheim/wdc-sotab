{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b985a4ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import multiprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7bc1156b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the ground truth files for SOTAB\n",
    "# cta_train_gt = pd.read_csv('data/CTA/CTA_training_gt.csv')\n",
    "# cta_val_gt = pd.read_csv('data/CTA/CTA_validation_gt.csv')\n",
    "# cta_test_gt = pd.read_csv('data/CTA/CTA_test_gt.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4fb7d2fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the ground truth files for SOTABv2\n",
    "cta_train_gt = pd.read_csv('SOTAB-v2/CTA/sotab_v2_cta_training_set.csv')\n",
    "cta_val_gt = pd.read_csv('SOTAB-v2/CTA/sotab_v2_cta_validation_set.csv')\n",
    "cta_test_gt = pd.read_csv('SOTAB-v2/CTA/sotab_v2_cta_test_set.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f987fd6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "gt = {'train':{}, 'val':{}, 'test':{}}\n",
    "for index, row in cta_train_gt.iterrows():\n",
    "    if row['table_name'] not in gt['train']:\n",
    "        gt['train'][row['table_name']] = {}\n",
    "        \n",
    "    gt['train'][row['table_name']][row['column_index']] = row['label']\n",
    "val = {}\n",
    "for index, row in cta_val_gt.iterrows():\n",
    "    if row['table_name'] not in gt['val']:\n",
    "        gt['val'][row['table_name']] = {} \n",
    "    gt['val'][row['table_name']][row['column_index']] = row['label']\n",
    "test = {}\n",
    "for index, row in cta_test_gt.iterrows():\n",
    "    if row['table_name'] not in gt['test']:\n",
    "        gt['test'][row['table_name']] = {}\n",
    "    gt['test'][row['table_name']][row['column_index']] = row['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "69b528b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "cta_train_cols = (cta_train_gt['table_name'] + '|' + cta_train_gt['column_index'].map(str) + '|' + cta_train_gt['label']).tolist()\n",
    "cta_val_cols = (cta_val_gt['table_name'] + '|' + cta_val_gt['column_index'].map(str) + '|' + cta_val_gt['label']).tolist()\n",
    "cta_test_cols = (cta_test_gt['table_name'] + '|' + cta_test_gt['column_index'].map(str) + '|' + cta_test_gt['label']).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "05d1bf3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "type_labels = list(cta_val_gt['label'].unique())\n",
    "print(len(type_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "07fdfaaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Simple Preprocessing\n",
    "\n",
    "def clean_text(text):        \n",
    "    if(isinstance(text, dict)):\n",
    "        text = ' '.join([ clean_text(v) for k, v in text.items()] )\n",
    "    elif(isinstance(text, list)):\n",
    "        text = map(clean_text, text)\n",
    "        text = ' '.join(text)\n",
    "        \n",
    "    if pd.isnull(text):\n",
    "        return ''\n",
    "        \n",
    "    #Remove excess whitespaces\n",
    "    text = re.sub(' +', ' ', str(text)).strip()\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "31d9739c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare format of input datasets for Doduo models: table_id, [labels], data, label_ids\n",
    "def get_table_column(column):\n",
    "    file_name, column_index, label = column.split('|')\n",
    "\n",
    "    if file_name in cta_train_gt['table_name'].tolist():\n",
    "        path = 'SOTAB-v2/CTA/Train/'+file_name # Path for train tables\n",
    "    elif file_name in cta_val_gt['table_name'].tolist():\n",
    "        path = 'SOTAB-v2/CTA/Validation/'+file_name # Path for validation tables\n",
    "    else:\n",
    "        path = 'SOTAB-v2/CTA/Test/'+file_name # Path for test tables\n",
    "\n",
    "    df = pd.read_json(path, compression='gzip', lines=True)\n",
    "\n",
    "    y = [0] * len(type_labels)\n",
    "    y[type_labels.index(label)] = 1\n",
    "\n",
    "    return [\n",
    "        file_name, #table_id\n",
    "        [label], #[labels]\n",
    "        clean_text(df.iloc[:, int(column_index)].tolist()), #data\n",
    "        y, #label_ids\n",
    "        column_index\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d6b6a7ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "pool = multiprocessing.Pool(processes=20)\n",
    "train_result = pool.map(get_table_column, cta_train_cols)\n",
    "val_result = pool.map(get_table_column, cta_val_cols)\n",
    "test_result = pool.map(get_table_column, cta_test_cols)\n",
    "pool.close()\n",
    "pool.join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dde85a13",
   "metadata": {},
   "outputs": [],
   "source": [
    "cta = {}\n",
    "cta['train'] = pd.DataFrame(train_result, columns=['table_id', 'labels', 'data', 'label_ids','column_index'])\n",
    "cta['dev'] = pd.DataFrame(val_result, columns=['table_id', 'labels', 'data', 'label_ids','column_index'])\n",
    "cta['test'] = pd.DataFrame(test_result, columns=['table_id', 'labels', 'data', 'label_ids','column_index'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07a0610f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy MLB from DODUO provided datasets\n",
    "import pickle\n",
    "with open('data/turl-datasets/table_rel_extraction_serialized.pkl', \"rb\") as f:\n",
    "    train = pickle.load(f)\n",
    "cta['mlb'] = train['mlb']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e955ea56",
   "metadata": {},
   "outputs": [],
   "source": [
    "cta['test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ce63c200",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "file_name='data/sotabv2/table_col_type_serialized.pkl'\n",
    "f = open(file_name,'wb')\n",
    "pickle.dump(cta,f)\n",
    "f.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
