{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85c4a4ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import multiprocessing\n",
    "from collections import Counter\n",
    "from skmultilearn.model_selection import iterative_train_test_split\n",
    "from skmultilearn.model_selection.measures import get_combination_wise_output_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bf86599",
   "metadata": {},
   "source": [
    "## Read the created dataset and attach column values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75f02e3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('output-data/cpa-datasets/dataset.csv')\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be199ef4",
   "metadata": {},
   "outputs": [],
   "source": [
    "col_table = (dataset['column_name']+'|'+dataset['file_name']).tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "915d5aa5",
   "metadata": {},
   "source": [
    "### Add value columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2c186de",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Existing English Tables\n",
    "existing = open(\"output-data/english_table_names.txt\", 'r')\n",
    "existing_english_tables = [line.replace('\\n', '') for line in existing.readlines()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cd529fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Returns values of cleaned textual columns\n",
    "def get_values(col_table_name):\n",
    "    column_name, file_name = col_table_name.split('|')\n",
    "    \n",
    "    if file_name in existing_english_tables:\n",
    "        file = 'output-data/expanded-tables/' + file_name\n",
    "    else:\n",
    "        file = 'output-data/new-english-tables/' + file_name\n",
    "    \n",
    "    #Open table\n",
    "    df = pd.read_json(file, compression='gzip', lines=True)\n",
    "           \n",
    "    return df[column_name].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5fd9db9",
   "metadata": {},
   "outputs": [],
   "source": [
    "pool = multiprocessing.Pool(processes=25)\n",
    "values = pool.map(get_values, col_table)\n",
    "pool.close()\n",
    "pool.join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bed2a087",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['values'] = values\n",
    "dataset = dataset.loc[~dataset['relation_label'].isin(['hasMenu', 'acceptsReservations'])]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bddc8ca3",
   "metadata": {},
   "source": [
    "## Create training, validation and test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b16e531f",
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_by_table = dataset.groupby(['file_name'])['relation_label'].apply(','.join).reset_index()\n",
    "grouped_by_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7ea1673",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = grouped_by_table[[\"file_name\"]].values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3302a60f",
   "metadata": {},
   "source": [
    "### One hot encoding of CPA labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84a1667d",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_labels = dataset['relation_label'].unique()\n",
    "y = np.zeros(shape=(len(grouped_by_table['file_name'].tolist()), len(all_labels))) #encoded labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf9597d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in grouped_by_table.iterrows():\n",
    "    table_labels = row['relation_label'].split(',')\n",
    "    count = 0\n",
    "    \n",
    "    for label in all_labels:\n",
    "        if label in table_labels:\n",
    "            y[index][count] = 1\n",
    "        else:\n",
    "            y[index][count] = 0\n",
    "        count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b754a4d9",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "X_train, y_train, X_test, y_test = iterative_train_test_split(X, y, test_size = 0.2)\n",
    "print('Training set length: '+str(len(X_train)) +', Testing set length: '+ str(len(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b7a6727",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Relation Labels in each set\n",
    "pd.DataFrame({\n",
    "    'train': Counter(str(combination) for row in get_combination_wise_output_matrix(y_train, order=1) for combination in row),\n",
    "    'test' : Counter(str(combination) for row in get_combination_wise_output_matrix(y_test, order=1) for combination in row)\n",
    "}).T.fillna(0.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee24143b",
   "metadata": {},
   "source": [
    "### Split testing set into validation and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9904e013",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val, y_val, X_test, y_test = iterative_train_test_split(X_test, y_test, test_size = 0.5)\n",
    "print('Validation set length: '+str(len(X_val)) +', Testing set length: '+ str(len(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67c4b1b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame({\n",
    "    'val': Counter(str(combination) for row in get_combination_wise_output_matrix(y_val, order=1) for combination in row),\n",
    "    'test' : Counter(str(combination) for row in get_combination_wise_output_matrix(y_test, order=1) for combination in row)\n",
    "}).T.fillna(0.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcab3a4a",
   "metadata": {},
   "source": [
    "## Statistics for each set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72aefd6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f52c6156",
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_by_table_dict = grouped_by_table.to_dict('records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef09d877",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dictionary with table names as key and relation labels as values\n",
    "file_to_label = {}\n",
    "for row in grouped_by_table_dict:\n",
    "    file_to_label[row['file_name']] = row['relation_label']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a113c0b6",
   "metadata": {},
   "source": [
    "### Training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6319619",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Count how many columns per label\n",
    "label_and_number_train = {}\n",
    "for row in X_train:\n",
    "    \n",
    "    for label in file_to_label[row[0]].split(','):\n",
    "        if label in label_and_number_train:\n",
    "            label_and_number_train[label] += 1\n",
    "        else:\n",
    "            label_and_number_train[label] = 1\n",
    "print('Number of unique relation labels in training set: '+ str(len(label_and_number_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "009ab4ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_and_number_train.values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c7fb4fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Minimum column count per label is: '+str(min(label_and_number_train.values())) )\n",
    "print('Maximum column count per label is: '+str(max(label_and_number_train.values())) )\n",
    "print('Total column count is: '+str(sum(label_and_number_train.values())) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96e9ce67",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,5))\n",
    "plt.hist(label_and_number_train.values(), bins=10)\n",
    "plt.ylabel('Label Count')\n",
    "plt.xlabel('Number of columns')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "749a7725",
   "metadata": {},
   "source": [
    "### Validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfeb1675",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Count how many columns per label\n",
    "label_and_number_val = {}\n",
    "for row in X_val:\n",
    "    \n",
    "    for label in file_to_label[row[0]].split(','):\n",
    "        if label in label_and_number_val:\n",
    "            label_and_number_val[label] += 1\n",
    "        else:\n",
    "            label_and_number_val[label] = 1\n",
    "print('Number of unique relation labels in validation set: '+ str(len(label_and_number_val)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac4b7ec7",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_and_number_val.values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be717978",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Minimum column count per label is: '+str(min(label_and_number_val.values())) )\n",
    "print('Maximum column count per label is: '+str(max(label_and_number_val.values())) )\n",
    "print('Total column count is: '+str(sum(label_and_number_val.values())) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0775b70",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,5))\n",
    "plt.hist(label_and_number_val.values(), bins=10)\n",
    "plt.ylabel('Label Count')\n",
    "plt.xlabel('Number of columns')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37ad560b",
   "metadata": {},
   "source": [
    "### Testing set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81cfea07",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Count how many columns per label\n",
    "label_and_number_test = {}\n",
    "for row in X_test:\n",
    "    \n",
    "    for label in file_to_label[row[0]].split(','):\n",
    "        if label in label_and_number_test:\n",
    "            label_and_number_test[label] += 1\n",
    "        else:\n",
    "            label_and_number_test[label] = 1\n",
    "print('Number of unique relation labels in testing set: '+ str(len(label_and_number_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e8a4f95",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_and_number_test.values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8d1dce7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Minimum column count per label is: '+str(min(label_and_number_test.values())) )\n",
    "print('Maximum column count per label is: '+str(max(label_and_number_test.values())) )\n",
    "print('Total column count is: '+str(sum(label_and_number_test.values())) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb931181",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,5))\n",
    "plt.hist(label_and_number_test.values(), bins=10)\n",
    "plt.ylabel('Label Count')\n",
    "plt.xlabel('Number of columns')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b01f38db",
   "metadata": {},
   "source": [
    "## Prepare csv file for each set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4866b169",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_tables = [ table[0] for table in X_train ]\n",
    "validation_tables = [ table[0] for table in X_val ]\n",
    "testing_tables = [ table[0] for table in X_test ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a107fc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set = dataset.loc[dataset['file_name'].isin(training_tables)]\n",
    "validation_set = dataset.loc[dataset['file_name'].isin(validation_tables)]\n",
    "testing_set = dataset.loc[dataset['file_name'].isin(testing_tables)]\n",
    "\n",
    "training_set = training_set.loc[training_set['relation_label'].isin(testing_set['relation_label'].unique())]\n",
    "validation_set = validation_set.loc[validation_set['relation_label'].isin(testing_set['relation_label'].unique())]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b16e94a",
   "metadata": {},
   "outputs": [],
   "source": [
    "rel_lbls = {}\n",
    "for index, row in testing_set.iterrows():\n",
    "    rel_lbls[row['column_name']] = row['relation_label']\n",
    "\n",
    "selection = {}\n",
    "for index, row in testing_set.iterrows():\n",
    "    if row['file_name'] not in selection:\n",
    "        selection[row['file_name']] = {}\n",
    "        \n",
    "    selection[row['file_name']][row['column_name']] = row['selection_type']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fbc115b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some manual transfer to Random\n",
    "selection_count = {\n",
    "    'Random': {},\n",
    "    'Value Heterogeneity': {},\n",
    "    'Corner Cases': {},\n",
    "    'Missing values': {}\n",
    "}\n",
    "for r in testing_set['relation_label'].unique():\n",
    "    print(r)\n",
    "    \n",
    "    selection_count['Random'][r] = []\n",
    "    selection_count['Value Heterogeneity'][r] = []\n",
    "    selection_count['Corner Cases'][r] = []\n",
    "    selection_count['Missing values'][r] = []\n",
    "for file in selection:\n",
    "    for col in selection[file]:\n",
    "        sel_type = selection[file][col]\n",
    "        selection_count[sel_type][rel_lbls[col]].append(col + '|' + file)\n",
    "transfer = []\n",
    "#alternateName\n",
    "for c in selection_count['Missing values']['alternateName']:\n",
    "    transfer.append(c)\n",
    "#additonalName\n",
    "transfer.append(selection_count['Missing values']['additionalName'][0])\n",
    "#homeLocation\n",
    "for c in selection_count['Corner Cases']['homeLocation'][:6]:\n",
    "    transfer.append(c)\n",
    "#episodeNumber\n",
    "for c in selection_count['Corner Cases']['episodeNumber']:\n",
    "    transfer.append(c)\n",
    "#alumniOf\n",
    "for c in selection_count['Missing values']['alumniOf'][:2]:\n",
    "    transfer.append(c)\n",
    "#checkInTime\n",
    "for c in selection_count['Missing values']['checkInTime'][:3]:\n",
    "    transfer.append(c)\n",
    "#checkOutTime\n",
    "for c in selection_count['Missing values']['checkoutTime'][:3]:\n",
    "    transfer.append(c)\n",
    "#honorificSuffix\n",
    "for c in selection_count['Missing values']['honorificSuffix']:\n",
    "    transfer.append(c)\n",
    "#homeTeam\n",
    "for c in selection_count['Corner Cases']['homeTeam']:\n",
    "    transfer.append(c)\n",
    "#awayTeam\n",
    "for c in selection_count['Corner Cases']['awayTeam']:\n",
    "    transfer.append(c)\n",
    "#award\n",
    "for c in selection_count['Missing values']['award']:\n",
    "    transfer.append(c)\n",
    "#memberOf\n",
    "for c in selection_count['Missing values']['memberOf'][:2]:\n",
    "    transfer.append(c)\n",
    "transfer.append(selection_count['Corner Cases']['memberOf'][0])\n",
    "#deathDate\n",
    "for c in selection_count['Value Heterogeneity']['deathDate'][:8]:\n",
    "    transfer.append(c)\n",
    "\n",
    "i = 0\n",
    "for file in selection:\n",
    "    for col in selection[file]:\n",
    "        if col + '|'+ file in transfer:\n",
    "            i += 1\n",
    "            selection[file][col] = 'Random'\n",
    "\n",
    "new_selection_types = []\n",
    "for index, row in testing_set.iterrows():\n",
    "    new_selection_types.append(selection[row['file_name']][row['column_name']])\n",
    "\n",
    "testing_set['selection_type'] = new_selection_types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6eb5a14",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set.to_csv('output-data/cpa-datasets/training_set.csv.gz', index=False, compression='gzip')\n",
    "validation_set.to_csv('output-data/cpa-datasets/validation_set.csv.gz', index=False, compression='gzip')\n",
    "testing_set.to_csv('output-data/cpa-datasets/testing_set.csv.gz', index=False, compression='gzip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13c76fa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('output-data/cpa-datasets/relation_vocab.txt', 'a') as file:\n",
    "    i = 0\n",
    "    for label in testing_set['relation_label'].unique():\n",
    "        file.write(str(i)+ '\\t' + label +'\\n')\n",
    "        i += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bed6c5d",
   "metadata": {},
   "source": [
    "### Create small subset of training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f37a7e05",
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_by_table = training_set.groupby(['file_name'])['relation_label'].apply(','.join).reset_index()\n",
    "grouped_by_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5d7a778",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = grouped_by_table[[\"file_name\"]].values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a50fa04d",
   "metadata": {},
   "source": [
    "### One hot encoding of CPA labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a795a1b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "r = open(\"output-data/cpa-datasets/relation_vocab.txt\", 'r')\n",
    "all_labels = [line.replace('\\n', '').split('\\t')[1] for line in r.readlines()]\n",
    "y = np.zeros(shape=(len(grouped_by_table['file_name'].tolist()), len(all_labels))) #encoded labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb301db0",
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in grouped_by_table.iterrows():\n",
    "    table_labels = row['relation_label'].split(',')\n",
    "    count = 0\n",
    "    \n",
    "    for label in all_labels:\n",
    "        if label in table_labels:\n",
    "            y[index][count] = 1\n",
    "        else:\n",
    "            y[index][count] = 0\n",
    "        count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "807ba3cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_rest, y_rest, X_test, y_test = iterative_train_test_split(X, y, test_size = 0.25)\n",
    "print('Training set length: '+str(len(X_rest)) +', Testing set length: '+ str(len(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87b235e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Relation Labels in each set\n",
    "pd.DataFrame({\n",
    "    'train': Counter(str(combination) for row in get_combination_wise_output_matrix(y_rest, order=1) for combination in row),\n",
    "    'test' : Counter(str(combination) for row in get_combination_wise_output_matrix(y_test, order=1) for combination in row)\n",
    "}).T.fillna(0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b0632c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_tables = [ table[0] for table in X_test ]\n",
    "training_set_small = training_set.loc[training_set['file_name'].isin(training_tables)]\n",
    "training_set_small"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0782b1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set_small.to_csv('output-data/cpa-datasets/training_set_small.csv.gz', index=False, compression='gzip')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
