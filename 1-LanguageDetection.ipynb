{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a19afdd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import zipfile\n",
    "import os\n",
    "import re\n",
    "import fasttext\n",
    "import spacy\n",
    "import multiprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "805fa65b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n"
     ]
    }
   ],
   "source": [
    "#Load fasttext model for language detection\n",
    "model = fasttext.load_model('data/fasttext-model/lid.176.bin')\n",
    "\n",
    "#Load spacy for named entity removal\n",
    "ne = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2411a673",
   "metadata": {},
   "source": [
    "## Language Detection for Column Similarity\n",
    "1. Discard columns that do not indicate the language.\n",
    "2. Discard numerical and datetime columns.\n",
    "3. Remove numbers in all column values.\n",
    "4. Remove punctuation\n",
    "5. Remove detected named entities in some cases.\n",
    "6. Detect language using fasttext model and create new tables with only English rows if a table is not in English."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dd0b502a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#1: Columns to discard as they are not indicative of the language\n",
    "ignore_columns = ['url','telephone','page_url', 'photo', 'image', 'name', 'sku', 'identifier', 'isbn', 'mpn', 'productid', 'gtin', 'vatid', 'taxid', 'faxnumber', 'geo', 'price', 'openinghoursspecification']\n",
    "\n",
    "#Import all datetime labels from schema.org\n",
    "datetime = open(\"data/schemaorg-vocabulary/datetime_labels.txt\", 'r')\n",
    "date_labels = [line.replace('\\n', '').lower() for line in datetime.readlines()]\n",
    "\n",
    "ignore_columns = ignore_columns + date_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3b0fe884",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Preprocessing methods:\n",
    "\n",
    "def clean_text(text):\n",
    "    \n",
    "    if pd.isnull(text):\n",
    "        return ''\n",
    "    \n",
    "    #3: Remove numbers\n",
    "    text = re.sub(r\"[0-9]\", \"\", str(text))\n",
    "    \n",
    "    #4: Remove punctuation\n",
    "    text = re.sub(r\"[^\\w\\s]\", \"\", str(text))\n",
    "    \n",
    "    #Remove excess whitespaces\n",
    "    text = re.sub(' +', ' ', str(text)).strip()\n",
    "    \n",
    "    return text\n",
    "\n",
    "#5: Remove detected named entities\n",
    "def clean_named_entities(text):\n",
    "    if(text == 'None'):\n",
    "        return ''\n",
    "    \n",
    "    #Remove named entities\n",
    "    document = ne(text)\n",
    "        \n",
    "    text = \" \".join([word.text for word in document if not word.ent_type_])\n",
    "    \n",
    "    return text\n",
    "\n",
    "#Return a flattened list\n",
    "def flatten_list(original_list):\n",
    "    flat_list = []\n",
    "    for item in original_list:\n",
    "        if isinstance(item, list):\n",
    "            flat_list = flat_list + item\n",
    "        else:\n",
    "            flat_list.append(item)\n",
    "    return flat_list\n",
    "\n",
    "#Preprocess rows\n",
    "def preprocess_row(row):\n",
    "    preprocessed_row = row\n",
    "    \n",
    "    #If the row is a dictionary, turn dictionary into list by removing keys\n",
    "    if(isinstance(row, dict)):\n",
    "        preprocessed_row = flatten_list([v for k, v in row.items()])\n",
    "    \n",
    "    #If row is a list, check if any value in the list is a dictionary\n",
    "    if(isinstance(preprocessed_row, list)):\n",
    "        preprocessed_row = flatten_list([preprocess_row(item) for item in preprocessed_row])\n",
    "    #Else if row is a string\n",
    "    else:\n",
    "        preprocessed_row = clean_text(row)\n",
    "    \n",
    "    return preprocessed_row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29d56115",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_rows_language(column_name, df, file_name):\n",
    "    #Dataframe to dictionary\n",
    "    df_to_dict = df.to_dict('records')\n",
    "\n",
    "    table = []\n",
    "    numdate_columns = list(df.select_dtypes(include=['number','datetime']).columns)\n",
    "    \n",
    "    #Check language of each row\n",
    "    for row in df_to_dict:\n",
    "        #If column value is None: text is all row, otherwise only column value\n",
    "        text = preprocess_row(row[column_name]) if column_name and row[column_name] else ' '.join([ clean_text(preprocess_row(row[col])) for col in df.columns if row[col] and col not in ignore_columns + numdate_columns])\n",
    "        row_is_english = False\n",
    "\n",
    "        if(clean_text(text)):\n",
    "            #Predict language of value/row\n",
    "            language = model.predict(clean_text(text))\n",
    "            confidence = language[1][0]\n",
    "            row_is_english = bool(language[0][0] == '__label__en')\n",
    "\n",
    "            #If confidence is low for English language check after removing named entities\n",
    "            if row_is_english and confidence < 0.5:                    \n",
    "                removed_entities_text = clean_text(clean_named_entities(text))\n",
    "                without_entities = model.predict(removed_entities_text)\n",
    "\n",
    "                #Row is considered English if:\n",
    "                # 1. The value of text is empty\n",
    "                # 2. English prediction, but low confidence\n",
    "                # 3. Not English prediction, but low confidence\n",
    "                row_is_english = bool(not removed_entities_text) | bool(without_entities[0][0] == '__label__en') | bool(bool(without_entities[0][0] != '__label__en') & bool(without_entities[1][0] < 0.5))\n",
    "\n",
    "            #Else if the language is not english but confidence is low ==> keep as english\n",
    "            elif not row_is_english and confidence < 0.5:\n",
    "                row_is_english = True\n",
    "\n",
    "        #Keep empty row values (could be due to removed numbers)        \n",
    "        else:\n",
    "            row_is_english = True\n",
    "\n",
    "        #If row is in English, add to new table\n",
    "        if row_is_english:\n",
    "            r = [row[col] for col in df.columns]\n",
    "            table.append(r)\n",
    "    \n",
    "    #If new table is the same length as original table, keep original table\n",
    "    if len(table) == len(df.index):\n",
    "        return True\n",
    "    \n",
    "    #If new table has at least 10 rows\n",
    "    if len(table) >= 10:\n",
    "        new_table = pd.DataFrame(table, columns=df.columns)\n",
    "        new_table.to_json(english_tables_path + file_name, orient='records', lines=True, compression='gzip')\n",
    "    \n",
    "    #Returns False because not all rows are in English\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "344091eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Method for when a column name (description or disambiguatingDescription) exists:\n",
    "#Check if all rows of the column for that column are in English\n",
    "def is_english_table_with_column(column_name, df, file_name):\n",
    "    \n",
    "    #Predict language for non-empty values of column\n",
    "    col_values = df[df[column_name].notna()][column_name].apply(lambda row: preprocess_row(row)).tolist()\n",
    "    \n",
    "    language = model.predict(flatten_list(col_values))\n",
    "    language_list = [item for sublist in language[0] for item in sublist]\n",
    "        \n",
    "    #If the table has all rows in a single language and with high confidence return true or false if english table\n",
    "    if len(set(language_list)) == 1 and all(conf >= 0.50 for conf in language[1]):\n",
    "        return bool(next(iter(set(language_list))) == '__label__en')\n",
    "    \n",
    "    #Else if the table has different languages in each row: Create a new table with rows in English\n",
    "    else:\n",
    "        check_rows_language(column_name, df, file_name)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95aa082b",
   "metadata": {},
   "source": [
    "## Detect English Tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cefb48e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Path where all downloaded top100 and minimum3 zip files are:\n",
    "original_data_path = 'data/stc_zip_files/'\n",
    "\n",
    "#Unzip all Schema.org Table corpus files in directory: data/original-corpus-data\n",
    "unzipped_path = 'data/original-corpus-data'\n",
    "for file in os.listdir(original_data_path):\n",
    "    with zipfile.ZipFile(original_data_path + file, 'r') as zip_ref:\n",
    "        zip_ref.extractall(unzipped_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f695116",
   "metadata": {},
   "outputs": [],
   "source": [
    "english_tables_path = 'output-data/new-english-tables/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c176ea97",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_english_tables(file_name):\n",
    "    \n",
    "    file = 'data/original-corpus-data/' + file_name\n",
    "    #Open table as dataframe\n",
    "    df = pd.read_json(file, compression='gzip', lines=True)\n",
    "    \n",
    "    #Drop row_id column\n",
    "    df.drop(['row_id'], axis=1, inplace=True)\n",
    "    \n",
    "    table_is_english = False\n",
    "\n",
    "    #Check if there is a description column which could indicate the language of the table\n",
    "    if('description' in df.columns):\n",
    "        table_is_english = is_english_table_with_column('description', df, file_name)\n",
    "\n",
    "    #Else check if there is a disambiguatingDescription column\n",
    "    elif('disambiguatingdescription' in df.columns):\n",
    "        table_is_english = is_english_table_with_column('disambiguatingdescription', df, file_name)\n",
    "    \n",
    "    #If not check all rows individually if they are in English, and create a table that has only these English rows\n",
    "    else:\n",
    "        table_is_english = check_rows_language( None, df, file_name)\n",
    "        \n",
    "    if table_is_english:\n",
    "        with open('output-data/english_table_names.txt', 'a') as file:\n",
    "            file.write(file_name+'\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e15966ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "#All file_names\n",
    "table_names = os.listdir('data/original-corpus-data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "42e3c1cf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pool = multiprocessing.Pool(processes=22)\n",
    "res = pool.map(find_english_tables, table_names)\n",
    "pool.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78343708",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "4c1e7879e052f45deb268cdbf8978495a26227b0ec1278f4c95689ed8929680f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
