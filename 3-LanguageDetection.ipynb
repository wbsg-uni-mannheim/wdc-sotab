{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a19afdd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import zipfile\n",
    "import os\n",
    "import re\n",
    "import fasttext\n",
    "import multiprocessing\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "805fa65b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load fasttext model for language detection\n",
    "model = fasttext.load_model('data/fasttext-model/lid.176.bin')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2411a673",
   "metadata": {},
   "source": [
    "## Language Detection for Column Similarity\n",
    "1. Discard columns that do not indicate the language.\n",
    "2. Discard numerical and datetime columns.\n",
    "3. Remove numbers in all column values.\n",
    "4. Remove punctuation\n",
    "5. Detect language using fasttext model and create new tables with only English rows if a table is not in English."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd0b502a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#1: Columns to discard as they are not indicative of the language\n",
    "ignore_columns = ['url','telephone','page_url', 'photo', 'image', 'name', 'sku', 'identifier', 'isbn', 'mpn', 'productid', 'gtin', 'vatid', 'taxid', 'faxnumber', 'geo', 'price', 'openinghoursspecification']\n",
    "\n",
    "#Import all datetime labels from schema.org\n",
    "datetime = open(\"data/schemaorg-vocabulary/datetime_labels.txt\", 'r')\n",
    "date_labels = [line.replace('\\n', '').lower() for line in datetime.readlines()]\n",
    "\n",
    "ignore_columns = ignore_columns + date_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b0fe884",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Preprocessing methods:\n",
    "\n",
    "def clean_text(text):\n",
    "    \n",
    "    if pd.isnull(text):\n",
    "        return ''\n",
    "    \n",
    "    #3: Remove numbers\n",
    "    text = re.sub(r\"[0-9]\", \"\", str(text))\n",
    "        \n",
    "    #4: Remove punctuation\n",
    "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
    "    \n",
    "    #Remove excess whitespaces\n",
    "    text = re.sub(' +', ' ', str(text)).strip()\n",
    "    \n",
    "    return text\n",
    "\n",
    "#Return a flattened list\n",
    "def flatten_list(original_list):\n",
    "    flat_list = []\n",
    "    for item in original_list:\n",
    "        if isinstance(item, list):\n",
    "            flat_list = flat_list + item\n",
    "        else:\n",
    "            flat_list.append(item)\n",
    "    return flat_list\n",
    "\n",
    "#Preprocess rows\n",
    "def preprocess_row(row):\n",
    "    preprocessed_row = row\n",
    "    \n",
    "    #If the row is a dictionary, turn dictionary into list by removing keys\n",
    "    if(isinstance(row, dict)):\n",
    "        preprocessed_row = ' '.join(flatten_list([preprocess_row(v) for k, v in row.items()]))\n",
    "    \n",
    "    #If row is a list, check if any value in the list is a dictionary\n",
    "    if(isinstance(preprocessed_row, list)):\n",
    "        preprocessed_row = ' '.join(flatten_list([preprocess_row(item) for item in preprocessed_row]))\n",
    "    #Else if row is a string\n",
    "    else:\n",
    "        preprocessed_row = clean_text(row)\n",
    "    \n",
    "    return preprocessed_row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29d56115",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_rows_language(column_name, df, file_name):\n",
    "    #Dataframe to dictionary\n",
    "    df_to_dict = df.to_dict('records')\n",
    "\n",
    "    table = []\n",
    "    numdate_columns = list(df.select_dtypes(include=['number','datetime']).columns)\n",
    "    \n",
    "    #Check language of each row\n",
    "    for row in df_to_dict:\n",
    "        #If column value is None: text is all row, otherwise only column value\n",
    "        text = preprocess_row(row[column_name]) if column_name and row[column_name] else ' '.join([ clean_text(preprocess_row(row[col])) for col in df.columns if row[col] and col not in ignore_columns + numdate_columns])\n",
    "        row_is_english = False\n",
    "\n",
    "        if(clean_text(text)):\n",
    "            #Predict language of value/row\n",
    "            language = model.predict(clean_text(text))\n",
    "            confidence = language[1][0]\n",
    "            \n",
    "            #Row is considered English if:\n",
    "            # 1. The value of text is empty\n",
    "            # 2. English prediction with high confidence\n",
    "            \n",
    "            row_is_english = bool(language[0][0] == '__label__en') & bool(confidence >= 0.5)\n",
    "\n",
    "        #Keep empty row values (could be due to removed numbers)        \n",
    "        else:\n",
    "            row_is_english = True\n",
    "\n",
    "        #If row is in English, add to new table\n",
    "        if row_is_english:\n",
    "            r = [row[col] for col in df.columns]\n",
    "            table.append(r)\n",
    "    \n",
    "    #If new table is the same length as original table, keep original table\n",
    "    if len(table) == len(df.index):\n",
    "        return True\n",
    "    \n",
    "    #If new table has at least 10 rows\n",
    "    if len(table) >= 10:\n",
    "        new_table = pd.DataFrame(table, columns=df.columns)\n",
    "        new_table.to_json(english_tables_path + file_name, orient='records', lines=True, compression='gzip')\n",
    "    \n",
    "    #Returns False because not all rows are in English\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "344091eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Method for when a column name (description or disambiguatingDescription) exists:\n",
    "#Check if all rows of the column for that column are in English\n",
    "def is_english_table_with_column(column_name, df, file_name):\n",
    "    \n",
    "    #Predict language for non-empty values of column\n",
    "    col_values = df[df[column_name].notna()][column_name].apply(lambda row: preprocess_row(row)).tolist()\n",
    "    \n",
    "    language = model.predict(flatten_list(col_values))\n",
    "    language_list = [item for sublist in language[0] for item in sublist]\n",
    "        \n",
    "    #If the table has all rows in a single language and with high confidence return true or false if english table\n",
    "    if len(set(language_list)) == 1 and all(conf >= 0.50 for conf in language[1]):\n",
    "        return bool(next(iter(set(language_list))) == '__label__en')\n",
    "    \n",
    "    #Else if the table has different languages in each row: Create a new table with rows in English\n",
    "    else:\n",
    "        check_rows_language(column_name, df, file_name)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95aa082b",
   "metadata": {},
   "source": [
    "## Detect English Tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f695116",
   "metadata": {},
   "outputs": [],
   "source": [
    "english_tables_path = 'output-data/new-english-tables/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c176ea97",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_english_tables(file_name):\n",
    "    \n",
    "    file = 'output-data/expanded-tables/' + file_name\n",
    "    #Open table as dataframe\n",
    "    df = pd.read_json(file, compression='gzip', lines=True)\n",
    "    \n",
    "    table_is_english = False\n",
    "\n",
    "    #Check if there is a description column which could indicate the language of the table\n",
    "    if('description' in df.columns):\n",
    "        table_is_english = is_english_table_with_column('description', df, file_name)\n",
    "\n",
    "    #Else check if there is a disambiguatingDescription column\n",
    "    elif('disambiguatingdescription' in df.columns):\n",
    "        table_is_english = is_english_table_with_column('disambiguatingdescription', df, file_name)\n",
    "    \n",
    "    #If not check all rows individually if they are in English, and create a table that has only these English rows\n",
    "    else:\n",
    "        table_is_english = check_rows_language( None, df, file_name)\n",
    "        \n",
    "    if table_is_english:\n",
    "        with open('output-data/english_table_names.txt', 'a') as file:\n",
    "            file.write(file_name+'\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e15966ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "#All file_names\n",
    "table_names = os.listdir('output-data/expanded-tables/')\n",
    "len(table_names)\n",
    "\n",
    "pool = multiprocessing.Pool(processes=30)\n",
    "res = pool.map(find_english_tables, table_names)\n",
    "pool.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "4c1e7879e052f45deb268cdbf8978495a26227b0ec1278f4c95689ed8929680f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
